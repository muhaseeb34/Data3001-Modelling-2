{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba86624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e7c84b",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/support-vector-regression-svr-one-of-the-most-flexible-yet-robust-prediction-algorithms-4d25fbdaca60/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72129198",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPPED = [\n",
    "    \"dist_360_SPEED\", \"dist_360_THROTTLE\", \"dist_360_STEER\", \"dist_360_BRAKE\",\n",
    "    \"dist_360_CURRENTLAPTIMEINMS\", \"dist_360_LAPDISTANCE\", \"dist_360_WORLDPOSITIONX\", \"dist_360_WORLDPOSITIONY\",\n",
    "    \"dist_360_WORLDFORWARDDIRX\", \"dist_360_WORLDFORWARDDIRY\", \"dist_360_YAW\", \"dist_360_PITCH\",\n",
    "    \"dist_360_ROLL\", \"dist_360_left_dist\", \"dist_360_right_dist\", \"dist_360_dist_apex_1\",\n",
    "    \"dist_360_dist_apex_2\", \"dist_360_angle_to_apex1\", \"dist_360_angle_to_apex2\", \"dist_360_proj_from_ref\",\n",
    "    \"dist_430_SPEED\", \"dist_430_THROTTLE\", \"dist_430_STEER\", \"dist_430_BRAKE\",\n",
    "    \"dist_430_CURRENTLAPTIMEINMS\", \"dist_430_LAPDISTANCE\", \"dist_430_WORLDPOSITIONX\", \"dist_430_WORLDPOSITIONY\",\n",
    "    \"dist_430_WORLDFORWARDDIRX\", \"dist_430_WORLDFORWARDDIRY\", \"dist_430_YAW\", \"dist_430_PITCH\",\n",
    "    \"dist_430_ROLL\", \"dist_430_left_dist\", \"dist_430_right_dist\", \"dist_430_dist_apex_1\",\n",
    "    \"dist_430_dist_apex_2\", \"dist_430_angle_to_apex1\", \"dist_430_angle_to_apex2\", \"dist_430_proj_from_ref\",\n",
    "    \"dist_530_SPEED\", \"dist_530_THROTTLE\", \"dist_530_STEER\", \"dist_530_BRAKE\",\n",
    "    \"dist_530_CURRENTLAPTIMEINMS\", \"dist_530_LAPDISTANCE\", \"dist_530_WORLDPOSITIONX\", \"dist_530_WORLDPOSITIONY\",\n",
    "    \"dist_530_WORLDFORWARDDIRX\", \"dist_530_WORLDFORWARDDIRY\", \"dist_530_YAW\", \"dist_530_PITCH\",\n",
    "    \"dist_530_ROLL\", \"dist_530_left_dist\", \"dist_530_right_dist\", \"dist_530_dist_apex_1\",\n",
    "    \"dist_530_dist_apex_2\", \"dist_530_angle_to_apex1\", \"dist_530_angle_to_apex2\", \"dist_530_proj_from_ref\",\n",
    "    \"BPS_right_dist\", \"BPE_right_dist\", \"THS_right_dist\", \"THE_right_dist\", \"STS_right_dist\",\n",
    "    \"STM_right_dist\", \"STE_right_dist\", \"APX1_right_dist\", \"APX2_right_dist\", \"BPS_CURRENTLAPTIMEINMS\",\n",
    "    \"BPE_CURRENTLAPTIMEINMS\", \"THS_CURRENTLAPTIMEINMS\", \"THE_CURRENTLAPTIMEINMS\", \"STS_CURRENTLAPTIMEINMS\",\n",
    "    \"STM_CURRENTLAPTIMEINMS\", \"STE_CURRENTLAPTIMEINMS\", \"APX1_CURRENTLAPTIMEINMS\", \"APX2_CURRENTLAPTIMEINMS\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf036d38",
   "metadata": {},
   "source": [
    "# Uploading Data and removing outliers and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "590375fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_data_product.csv\")\n",
    "data = data.dropna().drop_duplicates().drop(columns=DROPPED)\n",
    "target_mean = data[\"Target_CURRENTLAPTIMEINMS\"].mean()\n",
    "target_std = data[\"Target_CURRENTLAPTIMEINMS\"].std()\n",
    "data = data[data['Target_CURRENTLAPTIMEINMS'] < target_mean + 3 * target_std] # removes 12 longest times\n",
    "y = data[\"Target_CURRENTLAPTIMEINMS\"]\n",
    "X = data.drop(columns=[\"Target_CURRENTLAPTIMEINMS\", \"lap_id\", \"invalid_lap\"])\n",
    "\n",
    "target_columns = [\n",
    "    'target_CURRENTLAPTIMEINMS', '_LAPDISTANCE', '_WORLDPOSITIONX', \n",
    "    '_WORLDPOSITIONY', '_STEER', '_BRAKE', '_THROTTLE', '_SPEED',\n",
    "]\n",
    "\n",
    "selected_columns = [col for col in X.columns if col.endswith(tuple(target_columns))]\n",
    "\n",
    "X = X[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed0032d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=42)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_X_split = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "scaler_y_split = StandardScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "X_train_scaled = scaler_X_split.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X_split.transform(X_test)\n",
    "\n",
    "y_train_scaled = scaler_y_split.fit_transform(y_train.to_numpy().reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y_split.transform(y_test.to_numpy().reshape(-1, 1)).ravel()\n",
    "y_scaled = scaler_y.fit_transform(y.to_numpy().reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8984c7",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "### Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "m_info = mutual_info_regression(X, y)\n",
    "Scores = pd.DataFrame(sorted(zip(X.columns, m_info), key=lambda x: x[1], reverse=True), columns=[\"feature\", \"mi_score\"])\n",
    "pd.set_option('display.max_rows', 200)\n",
    "Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f229b04",
   "metadata": {},
   "source": [
    "# Detecting mutlicollinearity\n",
    "\n",
    "### Variance inflation factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467761ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "X = add_constant(X)\n",
    "vif_data['feature'] = X.columns\n",
    "vif_data[\"VIF\"] = [round(variance_inflation_factor(X.values, i), 4) for i in range(X.shape[1])]\n",
    "vif_data[vif_data[\"VIF\"] < 10].sort_values(by=\"VIF\")#.iloc[:,0]\n",
    "# vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9a8b29",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f83686b",
   "metadata": {},
   "source": [
    "### SVR (scaled data without feature selection and without addressing mutlicollinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c85a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 168 candidates, totalling 840 fits\n",
      "[LibSVM]Best parameters: {'C': 0.3, 'coef0': 1, 'degree': 2, 'epsilon': 0.0005, 'gamma': 'auto', 'kernel': 'poly', 'max_iter': -1, 'shrinking': True, 'tol': 1e-06, 'verbose': True}\n",
      "Best RMSE: 0.5267111780051136\n",
      "RMSE for poly kernel: 1411.7489241080818\n",
      "R² for poly kernel: 0.7493263530455132\n"
     ]
    }
   ],
   "source": [
    "poly_parameters = {\n",
    "    'kernel': ['poly'],\n",
    "    'degree': [2, 3, 4, 5, 6, 7, 8],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'coef0': [1, 3, 5],\n",
    "    'tol': [1e-6],\n",
    "    'C': [0.3, 0.5, 1, 10],\n",
    "    'epsilon': [0.0005],\n",
    "    'shrinking': [True],\n",
    "    'verbose': [True],\n",
    "    'max_iter': [-1]\n",
    "}\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "grid_poly = GridSearchCV(\n",
    "    estimator=SVR(),\n",
    "    param_grid=poly_parameters,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_poly.fit(X_train_scaled, y_train_scaled)\n",
    "print(\"Best parameters:\", grid_poly.best_params_)\n",
    "print(\"Best RMSE:\", abs(grid_poly.best_score_))\n",
    "y_pred_poly_scaled = grid_poly.predict(X_test_scaled)\n",
    "y_pred_poly = scaler_y_split.inverse_transform(y_pred_poly_scaled.reshape(-1,1))\n",
    "\n",
    "rmse_poly = root_mean_squared_error(y_pred_poly, y_test)\n",
    "r2_poly = r2_score(y_pred_poly, y_test)\n",
    "print(\"RMSE for poly kernel:\", rmse_poly)\n",
    "print(\"R² for poly kernel:\", r2_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fd3f24",
   "metadata": {},
   "source": [
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "[LibSVM]Best parameters: {'C': 0.3, 'coef0': 3, 'degree': 3, 'epsilon': 0.0005, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': -1, 'shrinking': True, 'tol': 1e-06, 'verbose': True}\n",
    "Best RMSE: 0.549755590951283\n",
    "RMSE for poly kernel: 1551.693230307914\n",
    "R² for poly kernel: 0.6867939663481857"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb89c30",
   "metadata": {},
   "source": [
    "<!-- Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "[LibSVM]Best parameters: {'C': 0.3, 'coef0': 3, 'degree': 3, 'epsilon': 0.0005, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': -1, 'shrinking': True, 'tol': 1e-06, 'verbose': True}\n",
    "Best RMSE: 0.549755590951283\n",
    "RMSE for poly kernel: 1551.693230307914\n",
    "R² for poly kernel: 0.6867939663481857 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1395f79d",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efefb2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM]\n",
      "4-fold CV RMSE:\n",
      "Fold RMSEs: [1279.737 1603.639 1805.64  2243.22 ]\n",
      "Mean RMSE : 1733.059\n",
      "Std  RMSE : 349.207\n",
      "\n",
      "4-fold CV R2:\n",
      "Fold RMSEs: [0.835 0.543 0.727 0.591]\n",
      "Mean RMSE : 0.674\n",
      "Std  RMSE : 0.115\n"
     ]
    }
   ],
   "source": [
    "fold_rmse = []\n",
    "fold_R2 = []\n",
    "\n",
    "for i in range(4):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25, random_state=i+4)\n",
    "    model = SVR(kernel='poly', degree=3, gamma='scale',\n",
    "                    coef0=3, tol=1e-3,C=0.1, epsilon=0.0005,\n",
    "                    shrinking=True, verbose=2,max_iter=-1)\n",
    "    \n",
    "    scaler_X_split = StandardScaler()\n",
    "    scaler_y_split = StandardScaler()\n",
    "    X_train_scaled = scaler_X_split.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X_split.transform(X_test)\n",
    "    y_train_scaled = scaler_y_split.fit_transform(y_train.to_numpy().reshape(-1, 1)).ravel()\n",
    "    y_test_scaled = scaler_y_split.transform(y_test.to_numpy().reshape(-1, 1)).ravel()\n",
    "\n",
    "    model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "    y_pred_poly_scaled = model.predict(X_test_scaled)\n",
    "    y_pred_poly = scaler_y_split.inverse_transform(y_pred_poly_scaled.reshape(-1,1))\n",
    "\n",
    "    fold_rmse.append(root_mean_squared_error(y_pred_poly, y_test))\n",
    "    fold_R2.append(r2_score(y_pred_poly, y_test))\n",
    "\n",
    "print(\"\\n4-fold CV RMSE:\")\n",
    "print(\"Fold RMSEs:\", np.round(fold_rmse, 3))\n",
    "print(\"Mean RMSE :\", np.round(np.mean(fold_rmse), 3))\n",
    "print(\"Std  RMSE :\", np.round(np.std(fold_rmse), 3))\n",
    "print(\"\\n4-fold CV R2:\")\n",
    "print(\"Fold RMSEs:\", np.round(fold_R2, 3))\n",
    "print(\"Mean RMSE :\", np.round(np.mean(fold_R2), 3))\n",
    "print(\"Std  RMSE :\", np.round(np.std(fold_R2), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d18f6e",
   "metadata": {},
   "source": [
    "mean rmse 1733"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dee9331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best parameters: {'C': 2, 'epsilon': 0.001, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "Best RMSE: 0.6609561496644532\n",
      "RMSE for rbf kernel: 2170.7917144779694\n",
      "R² for rbf kernel: -0.39805540023762354\n"
     ]
    }
   ],
   "source": [
    "rbf_parameters = {\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'tol': [1e-3],\n",
    "    'C': [1, 1.2, 2],\n",
    "    'epsilon': [0.001],\n",
    "    'shrinking': [True],\n",
    "    'verbose': [False],\n",
    "    'max_iter': [-1]\n",
    "}\n",
    "\n",
    "grid_rbf = GridSearchCV(\n",
    "    estimator=SVR(),\n",
    "    param_grid=rbf_parameters,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "grid_rbf.fit(X_train_scaled, y_train_scaled)\n",
    "print(\"Best parameters:\", grid_rbf.best_params_)\n",
    "print(\"Best RMSE:\", abs(grid_rbf.best_score_))\n",
    "y_pred_rbf_scaled = grid_rbf.predict(X_test_scaled)\n",
    "y_pred_rbf = scaler_y_split.inverse_transform(y_pred_rbf_scaled.reshape(-1,1))\n",
    "\n",
    "rmse_rbf = root_mean_squared_error(y_pred_rbf, y_test)\n",
    "r2_rbf = r2_score(y_pred_rbf, y_test)\n",
    "print(\"RMSE for rbf kernel:\", rmse_rbf)\n",
    "print(\"R² for rbf kernel:\", r2_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072f928c",
   "metadata": {},
   "source": [
    "# Finding optimum using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f8481240",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haseeb Ijaz\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVR-suggested first-brake setup (within observed range) ===\n",
      "BPS_SPEED: 316.8764\n",
      "BPS_THROTTLE: 0.0259\n",
      "BPS_STEER: -0.0086\n",
      "BPS_BRAKE: 0.0000\n",
      "BPS_LAPDISTANCE: 289.9898\n",
      "BPS_WORLDPOSITIONX: 249.7089\n",
      "BPS_WORLDPOSITIONY: 252.2799\n",
      "BPS_ext_LAPDISTANCE: 319.7515\n",
      "BPE_SPEED: 284.9766\n",
      "BPE_THROTTLE: 0.0859\n",
      "BPE_STEER: 0.1857\n",
      "BPE_BRAKE: 0.7587\n",
      "BPE_LAPDISTANCE: 308.9894\n",
      "BPE_WORLDPOSITIONX: 364.2086\n",
      "BPE_WORLDPOSITIONY: 270.1854\n",
      "BPE_ext_LAPDISTANCE: 380.7259\n",
      "THS_SPEED: 310.8271\n",
      "THS_THROTTLE: 0.5563\n",
      "THS_STEER: -0.0149\n",
      "THS_BRAKE: 0.1010\n",
      "THS_LAPDISTANCE: 198.4681\n",
      "THS_WORLDPOSITIONX: 288.2920\n",
      "THS_WORLDPOSITIONY: 321.3616\n",
      "THS_ext_LAPDISTANCE: 309.7240\n",
      "THE_SPEED: 173.9855\n",
      "THE_THROTTLE: 0.2880\n",
      "THE_STEER: 0.3508\n",
      "THE_BRAKE: 0.4633\n",
      "THE_LAPDISTANCE: 373.8134\n",
      "THE_WORLDPOSITIONX: 361.8980\n",
      "THE_WORLDPOSITIONY: 177.8730\n",
      "THE_ext_LAPDISTANCE: 484.3836\n",
      "STS_SPEED: 170.5146\n",
      "STS_THROTTLE: 0.6255\n",
      "STS_STEER: 0.0073\n",
      "STS_BRAKE: 0.1512\n",
      "STS_LAPDISTANCE: 361.3141\n",
      "STS_WORLDPOSITIONX: 359.7168\n",
      "STS_WORLDPOSITIONY: 210.7334\n",
      "STS_ext_LAPDISTANCE: 403.2872\n",
      "STM_SPEED: 193.7240\n",
      "STM_THROTTLE: 0.2937\n",
      "STM_STEER: -0.0007\n",
      "STM_BRAKE: 0.0909\n",
      "STM_LAPDISTANCE: 412.6278\n",
      "STM_WORLDPOSITIONX: 370.7005\n",
      "STM_WORLDPOSITIONY: 130.4626\n",
      "STE_SPEED: 248.0218\n",
      "STE_THROTTLE: 0.7077\n",
      "STE_STEER: -0.0001\n",
      "STE_BRAKE: 0.0000\n",
      "STE_LAPDISTANCE: 506.4262\n",
      "STE_WORLDPOSITIONX: 411.9832\n",
      "STE_WORLDPOSITIONY: 74.9804\n",
      "STE_ext_LAPDISTANCE: 545.3473\n",
      "APX1_SPEED: 179.7839\n",
      "APX1_THROTTLE: 0.9695\n",
      "APX1_STEER: 0.8088\n",
      "APX1_BRAKE: 0.3297\n",
      "APX1_LAPDISTANCE: 390.3260\n",
      "APX1_WORLDPOSITIONX: 375.6811\n",
      "APX1_WORLDPOSITIONY: 194.4949\n",
      "APX2_SPEED: 206.5712\n",
      "APX2_THROTTLE: 0.9265\n",
      "APX2_STEER: -0.1444\n",
      "APX2_BRAKE: 0.0000\n",
      "APX2_LAPDISTANCE: 495.6061\n",
      "APX2_WORLDPOSITIONX: 366.4601\n",
      "APX2_WORLDPOSITIONY: 92.2323\n",
      "Predicted Target_CURRENTLAPTIMEINMS: 11,606.669\n"
     ]
    }
   ],
   "source": [
    "# --- 7) Define a realistic search box (stay inside observed data) ---\n",
    "percentiles = (0.05, 0.95)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "y_scaled_df = pd.DataFrame(y_scaled, columns=[\"Target_CURRENTLAPTIMEINMS\"])\n",
    "\n",
    "bounds = {\n",
    "    f: (X_scaled_df[f].quantile(percentiles[0]), X_scaled_df[f].quantile(percentiles[1]))\n",
    "    for f in X_scaled_df.columns\n",
    "}\n",
    "\n",
    "# --- 8) Random search over SVR prediction surface to find min predicted target ---\n",
    "rng = np.random.default_rng(42)\n",
    "N = 50_000\n",
    "candidates = {\n",
    "    f: rng.uniform(low=b[0], high=b[1], size=N)\n",
    "    for f, b in bounds.items()\n",
    "}\n",
    "Xcand = pd.DataFrame(candidates)[X_scaled_df.columns]\n",
    "\n",
    "# Predict on scaled values\n",
    "ycand = grid_poly.predict(Xcand)\n",
    "\n",
    "# Inverse-transform both features and target\n",
    "ycand_unscaled = scaler_y.inverse_transform(ycand.reshape(-1, 1)).ravel()\n",
    "\n",
    "imin = int(np.argmin(ycand_unscaled))\n",
    "best_combo_scaled = Xcand.iloc[imin].to_frame().T  # one-row DataFrame\n",
    "best_combo_unscaled = pd.DataFrame(\n",
    "    scaler_X.inverse_transform(best_combo_scaled),\n",
    "    columns=X.columns\n",
    ")\n",
    "\n",
    "best_pred = ycand_unscaled[imin]\n",
    "\n",
    "print(\"\\n=== SVR-suggested first-brake setup (within observed range) ===\")\n",
    "for k, v in best_combo_unscaled.iloc[0].items():\n",
    "    print(f\"{k}: {v:,.4f}\")\n",
    "print(f\"Predicted Target_CURRENTLAPTIMEINMS: {best_pred:,.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc6f76",
   "metadata": {},
   "source": [
    "# Partial Poly Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d90d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example: 3 feature dataset (X1, X2, X3)\n",
    "# X is your input matrix with shape (n_samples, n_features)\n",
    "# y is your target variable\n",
    "X = np.random.rand(100, 3) * 10  # Random data with 3 features\n",
    "y = np.sin(X[:, 0]) + 0.5 * X[:, 1] + np.random.randn(100)  # Target variable with noise\n",
    "\n",
    "# Scaling the data\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "\n",
    "X_scaled = sc_X.fit_transform(X)\n",
    "y_scaled = sc_y.fit_transform(y.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Train the SVR model with a polynomial kernel\n",
    "svr_poly = SVR(kernel='poly', degree=3, C=100, epsilon=0.1)\n",
    "svr_poly.fit(X_scaled, y_scaled)\n",
    "\n",
    "# 1. Compute the 95th percentiles for each feature (for input ranges)\n",
    "percentiles = np.percentile(X, 95, axis=0)\n",
    "\n",
    "# 2. Plot Partial Poly Graphs for each feature\n",
    "for feature_index in range(X.shape[1]):\n",
    "    # Vary the current feature (e.g., X1) across the top 95 percentile range\n",
    "    feature_range = np.linspace(0, percentiles[feature_index], 1000).reshape(-1, 1)\n",
    "\n",
    "    # Fix the other features at their mean values\n",
    "    X_fixed = np.mean(X[:, np.arange(X.shape[1]) != feature_index], axis=0)\n",
    "\n",
    "    # Create the combined input data with the varied feature and fixed others\n",
    "    X_combined = np.hstack([feature_range, np.tile(X_fixed, (feature_range.shape[0], 1))])\n",
    "\n",
    "    # Scale the new data for prediction\n",
    "    X_combined_scaled = sc_X.transform(X_combined)\n",
    "\n",
    "    # Predict using the trained SVR model\n",
    "    y_pred_scaled = svr_poly.predict(X_combined_scaled)\n",
    "\n",
    "    # Inverse transform the predictions to get original scale\n",
    "    y_pred = sc_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "    # Plot the result\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(feature_range, y_pred, label=f\"SVR Polynomial Fit (Varying Feature {feature_index+1})\")\n",
    "    plt.title(f'Partial Poly Graph (Varying Feature {feature_index+1})')\n",
    "    plt.xlabel(f'Feature {feature_index+1}')\n",
    "    plt.ylabel('Predicted y')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 3. Plot Partial Dependence for Pairs of Features (2D Contour Plots)\n",
    "for i in range(X.shape[1]):\n",
    "    for j in range(i + 1, X.shape[1]):\n",
    "        # Create a grid of values for Feature i and Feature j\n",
    "        feature1_range = np.linspace(0, percentiles[i], 100)\n",
    "        feature2_range = np.linspace(0, percentiles[j], 100)\n",
    "        \n",
    "        # Create a meshgrid for the 2D grid of Feature i and Feature j\n",
    "        feature1_grid, feature2_grid = np.meshgrid(feature1_range, feature2_range)\n",
    "        \n",
    "        # Create a combined grid of features for prediction\n",
    "        X_grid = np.vstack([feature1_grid.ravel(), feature2_grid.ravel()]).T\n",
    "        \n",
    "        # Fix the other features at their mean value\n",
    "        X_fixed = np.mean(X[:, [k for k in range(X.shape[1]) if k != i and k != j]], axis=0)\n",
    "        \n",
    "        # Combine the grid values with the fixed feature values\n",
    "        X_combined = np.hstack([X_grid, np.full((X_grid.shape[0], len(X_fixed)), X_fixed)])\n",
    "\n",
    "        # Scale the new data for prediction\n",
    "        X_combined_scaled = sc_X.transform(X_combined)\n",
    "\n",
    "        # Predict using the trained SVR model\n",
    "        y_pred_scaled = svr_poly.predict(X_combined_scaled)\n",
    "\n",
    "        # Inverse transform the predictions to get original scale\n",
    "        y_pred = sc_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "        # Reshape the predictions back into the grid shape\n",
    "        y_pred_grid = y_pred.reshape(feature1_grid.shape)\n",
    "\n",
    "        # Plot the results as a contour plot (for 2D data)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.contourf(feature1_range, feature2_range, y_pred_grid, levels=50, cmap='coolwarm')\n",
    "        plt.colorbar(label='Predicted y')\n",
    "        plt.title(f'Partial Dependence (Varying Features {i+1} and {j+1})')\n",
    "        plt.xlabel(f'Feature {i+1}')\n",
    "        plt.ylabel(f'Feature {j+1}')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly_parameters = {\n",
    "#     'kernel': ['poly'],\n",
    "#     'degree': [3, 5, 7, 9],\n",
    "#     'gamma': ['scale', 'auto'],\n",
    "#     'coef0': [0, 1, 3],\n",
    "#     'tol': [1e-3],\n",
    "#     'C': [0.01, 0.1, 1],\n",
    "#     'epsilon': [0.01, 0.05, 0.1, 1],\n",
    "#     'shrinking': [True],\n",
    "#     'verbose': [False],\n",
    "#     'max_iter': [-1]\n",
    "# }\n",
    "\n",
    "\n",
    "# rbf_parameters = {\n",
    "#     'kernel': ['rbf'],\n",
    "#     'gamma': ['scale', 'auto'],\n",
    "#     'tol': [1e-3],\n",
    "#     'C': [0.01, 0.1, 1],\n",
    "#     'epsilon': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "#     'shrinking': [True],\n",
    "#     'verbose': [False],\n",
    "#     'max_iter': [-1]\n",
    "# }\n",
    "# grid_poly = GridSearchCV(\n",
    "#     estimator=SVR(),\n",
    "#     param_grid=poly_parameters,\n",
    "#     cv=5,\n",
    "#     scoring='neg_root_mean_squared_error', # check others\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# grid_poly.fit(X_train_scaled, y_train)\n",
    "# print(\"Best parameters:\", grid_poly.best_params_)\n",
    "# print(\"Best RMSE:\", abs(grid_poly.best_score_))\n",
    "\n",
    "# grid_rbf = GridSearchCV(\n",
    "#     estimator=SVR(),\n",
    "#     param_grid=rbf_parameters,\n",
    "#     cv=5,\n",
    "#     scoring='neg_root_mean_squared_error', # check others\n",
    "#     n_jobs=-1,\n",
    "#     verbose=3\n",
    "# ) \n",
    "\n",
    "# grid_rbf.fit(X_train_scaled, y_train)\n",
    "# print(\"Best parameters:\", grid_rbf.best_params_)\n",
    "# print(\"Best RMSE:\", abs(grid_rbf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d5da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_parameters = {\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'tol': [1e-3],\n",
    "    'C': [0.01, 0.1, 1],\n",
    "    'epsilon': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "    'shrinking': [True],\n",
    "    'verbose': [False],\n",
    "    'max_iter': [-1]\n",
    "}\n",
    "\n",
    "grid_rbf = GridSearchCV(\n",
    "    estimator=SVR(),\n",
    "    param_grid=rbf_parameters,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error', # check others\n",
    "    n_jobs=-1,\n",
    "    verbose=3\n",
    ") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
