{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba86624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72129198",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPPED = [\n",
    "    \"dist_360_SPEED\", \"dist_360_THROTTLE\", \"dist_360_STEER\", \"dist_360_BRAKE\",\n",
    "    \"dist_360_CURRENTLAPTIMEINMS\", \"dist_360_LAPDISTANCE\", \"dist_360_WORLDPOSITIONX\", \"dist_360_WORLDPOSITIONY\",\n",
    "    \"dist_360_WORLDFORWARDDIRX\", \"dist_360_WORLDFORWARDDIRY\", \"dist_360_YAW\", \"dist_360_PITCH\",\n",
    "    \"dist_360_ROLL\", \"dist_360_left_dist\", \"dist_360_right_dist\", \"dist_360_dist_apex_1\",\n",
    "    \"dist_360_dist_apex_2\", \"dist_360_angle_to_apex1\", \"dist_360_angle_to_apex2\", \"dist_360_proj_from_ref\",\n",
    "    \"dist_430_SPEED\", \"dist_430_THROTTLE\", \"dist_430_STEER\", \"dist_430_BRAKE\",\n",
    "    \"dist_430_CURRENTLAPTIMEINMS\", \"dist_430_LAPDISTANCE\", \"dist_430_WORLDPOSITIONX\", \"dist_430_WORLDPOSITIONY\",\n",
    "    \"dist_430_WORLDFORWARDDIRX\", \"dist_430_WORLDFORWARDDIRY\", \"dist_430_YAW\", \"dist_430_PITCH\",\n",
    "    \"dist_430_ROLL\", \"dist_430_left_dist\", \"dist_430_right_dist\", \"dist_430_dist_apex_1\",\n",
    "    \"dist_430_dist_apex_2\", \"dist_430_angle_to_apex1\", \"dist_430_angle_to_apex2\", \"dist_430_proj_from_ref\",\n",
    "    \"dist_530_SPEED\", \"dist_530_THROTTLE\", \"dist_530_STEER\", \"dist_530_BRAKE\",\n",
    "    \"dist_530_CURRENTLAPTIMEINMS\", \"dist_530_LAPDISTANCE\", \"dist_530_WORLDPOSITIONX\", \"dist_530_WORLDPOSITIONY\",\n",
    "    \"dist_530_WORLDFORWARDDIRX\", \"dist_530_WORLDFORWARDDIRY\", \"dist_530_YAW\", \"dist_530_PITCH\",\n",
    "    \"dist_530_ROLL\", \"dist_530_left_dist\", \"dist_530_right_dist\", \"dist_530_dist_apex_1\",\n",
    "    \"dist_530_dist_apex_2\", \"dist_530_angle_to_apex1\", \"dist_530_angle_to_apex2\", \"dist_530_proj_from_ref\",\n",
    "    \"BPS_right_dist\", \"BPE_right_dist\", \"THS_right_dist\", \"THE_right_dist\", \"STS_right_dist\",\n",
    "    \"STM_right_dist\", \"STE_right_dist\", \"APX1_right_dist\", \"APX2_right_dist\", \"BPS_CURRENTLAPTIMEINMS\",\n",
    "    \"BPE_CURRENTLAPTIMEINMS\", \"THS_CURRENTLAPTIMEINMS\", \"THE_CURRENTLAPTIMEINMS\", \"STS_CURRENTLAPTIMEINMS\",\n",
    "    \"STM_CURRENTLAPTIMEINMS\", \"STE_CURRENTLAPTIMEINMS\", \"APX1_CURRENTLAPTIMEINMS\", \"APX2_CURRENTLAPTIMEINMS\"\n",
    "]\n",
    "\n",
    "UNION = [\"lap_id\", \"invalid_lap\", 'APX1_BRAKE', 'APX1_SPEED', 'APX1_STEER', 'APX1_WORLDFORWARDDIRX', 'APX1_WORLDPOSITIONX', 'APX1_WORLDPOSITIONY',\n",
    "         'APX1_YAW', 'APX1_angle_to_apex2', 'APX1_dist_apex_1', 'APX1_left_dist', 'APX1_proj_from_ref', 'APX2_PITCH',\n",
    "         'APX2_SPEED', 'APX2_STEER', 'APX2_THROTTLE', 'APX2_WORLDFORWARDDIRY', 'APX2_WORLDPOSITIONY', 'APX2_YAW',\n",
    "         'APX2_angle_to_apex1', 'APX2_angle_to_apex2', 'APX2_dist_apex_1', 'BPE_LAPDISTANCE', 'BPE_ROLL', 'BPE_SPEED',\n",
    "         'BPE_STEER', 'BPE_WORLDFORWARDDIRX', 'BPE_WORLDFORWARDDIRY', 'BPE_YAW', 'BPE_angle_to_apex1', 'BPE_angle_to_apex2',\n",
    "         'BPE_dist_apex_1', 'BPE_ext_TIMETOINMS', 'BPE_left_dist', 'BPE_proj_from_ref', 'BPS_PITCH', 'BPS_ROLL',\n",
    "         'BPS_SPEED', 'BPS_STEER', 'BPS_THROTTLE', 'BPS_WORLDPOSITIONX', 'BPS_YAW', 'BPS_angle_to_apex1',\n",
    "         'BPS_ext_TIMETOINMS', 'BPS_left_dist', 'STE_LAPDISTANCE', 'STE_PITCH', 'STE_ROLL', 'STE_SPEED',\n",
    "         'STE_STEER', 'STE_THROTTLE', 'THS_WORLDFORWARDDIRX', 'STE_WORLDFORWARDDIRX',\n",
    "         'STE_WORLDFORWARDDIRY', 'STE_YAW', 'STE_angle_to_apex1', 'STE_angle_to_apex2',\n",
    "         'STE_dist_apex_1', 'STE_ext_LAPDISTANCE', 'STE_ext_TIMETOINMS', 'STE_proj_from_ref', 'STM_BRAKE',\n",
    "         'STM_LAPDISTANCE', 'BPS_left_dist', 'STM_ROLL', 'STM_SPEED', 'STM_STEER', 'STM_THROTTLE',\n",
    "         'STM_THROTTLE', 'STE_LAPDISTANCE', 'STM_WORLDFORWARDDIRX', 'STM_WORLDFORWARDDIRX', 'STE_YAW', 'STM_WORLDFORWARDDIRY',\n",
    "         'STM_WORLDPOSITIONX', 'THS_PITCH', 'STM_WORLDPOSITIONY', 'STM_YAW', 'STM_angle_to_apex1',\n",
    "         'STM_angle_to_apex2', 'STE_angle_to_apex2', 'STM_dist_apex_1', 'STM_left_dist', 'STS_BRAKE', 'STS_LAPDISTANCE',\n",
    "         'STS_PITCH', 'STS_SPEED', 'STS_STEER', 'STS_THROTTLE', 'STS_WORLDFORWARDDIRX', 'STS_WORLDFORWARDDIRY',\n",
    "         'STS_WORLDPOSITIONX', 'STS_WORLDPOSITIONY', 'STS_YAW', 'APX2_YAW', 'STS_angle_to_apex1', 'STS_angle_to_apex2',\n",
    "         'STS_dist_apex_2', 'STS_ext_LAPDISTANCE', 'STS_ext_TIMETOINMS', 'APX1_WORLDPOSITIONX',\n",
    "         'STS_left_dist', 'STS_proj_from_ref', 'THE_BRAKE', 'THE_LAPDISTANCE', 'THE_ROLL', 'THE_SPEED', 'THE_WORLDFORWARDDIRX',\n",
    "         'THE_YAW', 'THE_dist_apex_1', 'THE_dist_apex_2', 'THE_ext_LAPDISTANCE', 'THE_ext_TIMETOINMS', 'THE_proj_from_ref',\n",
    "         'THS_PITCH', 'THS_ROLL', 'THS_SPEED', 'THS_SPEED', 'APX1_left_dist', 'THS_STEER', 'THS_THROTTLE', 'THS_WORLDFORWARDDIRX',\n",
    "         'THS_WORLDFORWARDDIRY', 'THS_WORLDPOSITIONY', 'THS_YAW', 'THS_ext_LAPDISTANCE', 'THS_ext_TIMETOINMS', 'THS_proj_from_ref'\n",
    "]\n",
    "\n",
    "TARGET = [\"Target_CURRENTLAPTIMEINMS\"]\n",
    "\n",
    "selected_features = [\n",
    "    \"APX1_BRAKE\", \"APX1_SPEED\", \"APX1_STEER\", \"APX1_WORLDFORWARDDIRX\",\n",
    "    \"APX1_YAW\", \"APX1_angle_to_apex2\", \"APX1_proj_from_ref\", \"APX2_SPEED\",\n",
    "    \"APX2_STEER\", \"APX2_THROTTLE\", \"APX2_WORLDPOSITIONY\", \"APX2_angle_to_apex1\",\n",
    "    \"APX2_angle_to_apex2\", \"APX2_dist_apex_1\", \"BPE_ROLL\", \"BPE_STEER\",\n",
    "    \"BPE_WORLDFORWARDDIRY\", \"BPE_YAW\", \"BPE_angle_to_apex1\", \"BPE_angle_to_apex2\",\n",
    "    \"BPE_ext_TIMETOINMS\", \"BPE_left_dist\", \"BPE_proj_from_ref\", \"BPS_PITCH\",\n",
    "    \"BPS_ROLL\", \"BPS_STEER\", \"BPS_THROTTLE\", \"BPS_YAW\",\n",
    "    \"BPS_angle_to_apex1\", \"BPS_ext_TIMETOINMS\", \"STE_ROLL\", \"STE_STEER\",\n",
    "    \"STE_THROTTLE\", \"STE_angle_to_apex1\", \"STE_ext_LAPDISTANCE\", \"STE_ext_TIMETOINMS\",\n",
    "    \"STE_proj_from_ref\", \"STM_BRAKE\", \"STM_ROLL\", \"STM_SPEED\",\n",
    "    \"STM_STEER\", \"STM_WORLDFORWARDDIRY\", \"STM_YAW\", \"STM_angle_to_apex1\",\n",
    "    \"STM_angle_to_apex2\", \"STM_left_dist\", \"STS_BRAKE\", \"STS_STEER\",\n",
    "    \"STS_THROTTLE\", \"STS_angle_to_apex1\", \"STS_angle_to_apex2\", \"STS_ext_TIMETOINMS\",\n",
    "    \"STS_proj_from_ref\", \"THE_BRAKE\", \"THE_ROLL\", \"THE_SPEED\",\n",
    "    \"THE_WORLDFORWARDDIRX\", \"THE_YAW\", \"THE_dist_apex_1\", \"THE_proj_from_ref\",\n",
    "    \"THS_ROLL\", \"THS_STEER\", \"THS_THROTTLE\", \"THS_YAW\",\n",
    "    \"THS_proj_from_ref\"\n",
    "]\n",
    "\n",
    "another_selected_features = [\n",
    "    \"APX2_SPEED\", \"STM_SPEED\", \"STE_ext_TIMETOINMS\", \"STS_angle_to_apex1\",\n",
    "    \"APX2_STEER\", \"THS_proj_from_ref\", \"STE_THROTTLE\", \"APX1_SPEED\",\n",
    "    \"STM_angle_to_apex2\", \"STE_proj_from_ref\", \"THE_ROLL\", \"STE_ext_LAPDISTANCE\",\n",
    "    \"STS_ext_TIMETOINMS\", \"THE_SPEED\", \"BPS_angle_to_apex1\", \"STM_YAW\",\n",
    "    \"STE_STEER\", \"APX1_YAW\", \"APX1_WORLDFORWARDDIRX\", \"APX2_THROTTLE\",\n",
    "    \"APX1_proj_from_ref\", \"STE_angle_to_apex1\", \"BPS_ROLL\", \"STS_BRAKE\",\n",
    "    \"THE_YAW\", \"STE_ROLL\", \"STS_proj_from_ref\", \"THE_WORLDFORWARDDIRX\",\n",
    "    \"BPE_angle_to_apex1\", \"BPE_WORLDFORWARDDIRY\", \"APX2_angle_to_apex1\", \"THS_ROLL\",\n",
    "    \"BPE_proj_from_ref\", \"THS_THROTTLE\", \"BPS_PITCH\", \"BPS_THROTTLE\",\n",
    "    \"STS_angle_to_apex2\", \"THE_proj_from_ref\", \"APX1_BRAKE\", \"BPE_angle_to_apex2\",\n",
    "    \"THS_YAW\", \"BPE_YAW\", \"APX2_angle_to_apex2\", \"BPE_ROLL\",\n",
    "    \"BPS_YAW\", \"BPE_ext_TIMETOINMS\", \"APX1_STEER\", \"APX1_angle_to_apex2\",\n",
    "    \"BPS_STEER\", \"STM_angle_to_apex1\", \"STM_left_dist\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf036d38",
   "metadata": {},
   "source": [
    "# Uploading Data and removing outliers and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "590375fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_data_product.csv\")\n",
    "data = data.dropna().drop_duplicates().drop(columns=DROPPED)\n",
    "target_mean = data[\"Target_CURRENTLAPTIMEINMS\"].mean()\n",
    "target_std = data[\"Target_CURRENTLAPTIMEINMS\"].std()\n",
    "data = data[data['Target_CURRENTLAPTIMEINMS'] < target_mean + 3 * target_std] # removes 12 longest times\n",
    "y = data[\"Target_CURRENTLAPTIMEINMS\"]\n",
    "X = data.drop(columns=[\"Target_CURRENTLAPTIMEINMS\", \"lap_id\", \"invalid_lap\"])\n",
    "\n",
    "target_columns = [\n",
    "    'target_CURRENTLAPTIMEINMS', '_LAPDISTANCE', '_WORLDPOSITIONX', \n",
    "    '_WORLDPOSITIONY', '_STEER', '_BRAKE', '_THROTTLE', '_SPEED',\n",
    "]\n",
    "\n",
    "selected_columns = [col for col in X.columns if col.endswith(tuple(target_columns))]\n",
    "\n",
    "X = X[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed0032d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=42)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_X_split = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "scaler_y_split = StandardScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "X_train_scaled = scaler_X_split.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X_split.transform(X_test)\n",
    "\n",
    "y_train_scaled = scaler_y_split.fit_transform(y_train.to_numpy().reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y_split.transform(y_test.to_numpy().reshape(-1, 1)).ravel()\n",
    "y_scaled = scaler_y.fit_transform(y.to_numpy().reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8984c7",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "### Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "m_info = mutual_info_regression(X, y)\n",
    "Scores = pd.DataFrame(sorted(zip(X.columns, m_info), key=lambda x: x[1], reverse=True), columns=[\"feature\", \"mi_score\"])\n",
    "pd.set_option('display.max_rows', 200)\n",
    "Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f229b04",
   "metadata": {},
   "source": [
    "# Detecting mutlicollinearity\n",
    "\n",
    "### Variance inflation factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467761ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "X = add_constant(X)\n",
    "vif_data['feature'] = X.columns\n",
    "vif_data[\"VIF\"] = [round(variance_inflation_factor(X.values, i), 4) for i in range(X.shape[1])]\n",
    "vif_data[vif_data[\"VIF\"] < 10].sort_values(by=\"VIF\")#.iloc[:,0]\n",
    "# vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f83686b",
   "metadata": {},
   "source": [
    "### SVR (scaled data without feature selection and without addressing mutlicollinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "187c85a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n",
      "[LibSVM]Best parameters: {'C': 0.1, 'coef0': 3, 'degree': 4, 'epsilon': 0.0005, 'gamma': 'auto', 'kernel': 'poly', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': True}\n",
      "Best RMSE: 0.5582914855619413\n"
     ]
    }
   ],
   "source": [
    "poly_parameters = {\n",
    "    'kernel': ['poly'],\n",
    "    'degree': [4, 5, 6, 7, 8],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'coef0': [1, 3, 5, 7],\n",
    "    'tol': [1e-3],\n",
    "    'C': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'epsilon': [0.0005, 0.001, 0.005],\n",
    "    'shrinking': [True],\n",
    "    'verbose': [True],\n",
    "    'max_iter': [-1]\n",
    "}\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "grid_poly = GridSearchCV(\n",
    "    estimator=SVR(),\n",
    "    param_grid=poly_parameters,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_poly.fit(X_train_scaled, y_train_scaled)\n",
    "print(\"Best parameters:\", grid_poly.best_params_)\n",
    "print(\"Best RMSE:\", abs(grid_poly.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c8bb7",
   "metadata": {},
   "source": [
    "Fitting 5 folds for each of 2940 candidates, totalling 14700 fits\n",
    "[LibSVM]Best parameters: {'C': 0.1, 'coef0': 7, 'degree': 5, 'epsilon': 0.0001, 'gamma': 'auto', 'kernel': 'poly', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': True}\n",
    "Best RMSE: 2507.1384803500814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "144a9daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for poly kernel: 1567.4278728766405\n",
      "R² for poly kernel: -25.199114917958326\n"
     ]
    }
   ],
   "source": [
    "y_pred_poly_scaled = grid_poly.predict(X_test_scaled)\n",
    "y_pred_poly = scaler_y_split.inverse_transform(y_pred_poly_scaled.reshape(-1,1))\n",
    "y_test_unscaled = scaler_y_split.inverse_transform(y_test_scaled.reshape(-1, 1))\n",
    "\n",
    "rmse_poly = root_mean_squared_error(y_pred_poly, y_test)\n",
    "r2_poly = r2_score(y_pred_poly, y_test_scaled)\n",
    "print(\"RMSE for poly kernel:\", rmse_poly)\n",
    "print(\"R² for poly kernel:\", r2_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efefb2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5-fold CV RMSE:\n",
      "Fold RMSEs: [0.55  0.397 0.593]\n",
      "Mean RMSE : 0.514\n",
      "Std  RMSE : 0.084\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "rmse_cv_poly = cross_val_score(grid_poly, X_scaled, y_scaled, scoring=\"neg_root_mean_squared_error\", cv=cv, n_jobs=-1)\n",
    "\n",
    "print(\"\\n5-fold CV RMSE:\")\n",
    "print(\"Fold RMSEs:\", np.round(-rmse_cv_poly, 3))\n",
    "print(\"Mean RMSE :\", np.round(-rmse_cv_poly.mean(), 3))\n",
    "print(\"Std  RMSE :\", np.round(rmse_cv_poly.std(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly_parameters = {\n",
    "#     'kernel': ['poly'],\n",
    "#     'degree': [3, 5, 7, 9],\n",
    "#     'gamma': ['scale', 'auto'],\n",
    "#     'coef0': [0, 1, 3],\n",
    "#     'tol': [1e-3],\n",
    "#     'C': [0.01, 0.1, 1],\n",
    "#     'epsilon': [0.01, 0.05, 0.1, 1],\n",
    "#     'shrinking': [True],\n",
    "#     'verbose': [False],\n",
    "#     'max_iter': [-1]\n",
    "# }\n",
    "\n",
    "\n",
    "# rbf_parameters = {\n",
    "#     'kernel': ['rbf'],\n",
    "#     'gamma': ['scale', 'auto'],\n",
    "#     'tol': [1e-3],\n",
    "#     'C': [0.01, 0.1, 1],\n",
    "#     'epsilon': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "#     'shrinking': [True],\n",
    "#     'verbose': [False],\n",
    "#     'max_iter': [-1]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13729d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_poly = GridSearchCV(\n",
    "#     estimator=SVR(),\n",
    "#     param_grid=poly_parameters,\n",
    "#     cv=5,\n",
    "#     scoring='neg_root_mean_squared_error', # check others\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# grid_poly.fit(X_train_scaled, y_train)\n",
    "# print(\"Best parameters:\", grid_poly.best_params_)\n",
    "# print(\"Best RMSE:\", abs(grid_poly.best_score_))\n",
    "\n",
    "# grid_rbf = GridSearchCV(\n",
    "#     estimator=SVR(),\n",
    "#     param_grid=rbf_parameters,\n",
    "#     cv=5,\n",
    "#     scoring='neg_root_mean_squared_error', # check others\n",
    "#     n_jobs=-1,\n",
    "#     verbose=3\n",
    "# )\n",
    "\n",
    "# grid_rbf.fit(X_train_scaled, y_train)\n",
    "# print(\"Best parameters:\", grid_rbf.best_params_)\n",
    "# print(\"Best RMSE:\", abs(grid_rbf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc6f76",
   "metadata": {},
   "source": [
    "# Partial Poly Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d90d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example: 3 feature dataset (X1, X2, X3)\n",
    "# X is your input matrix with shape (n_samples, n_features)\n",
    "# y is your target variable\n",
    "X = np.random.rand(100, 3) * 10  # Random data with 3 features\n",
    "y = np.sin(X[:, 0]) + 0.5 * X[:, 1] + np.random.randn(100)  # Target variable with noise\n",
    "\n",
    "# Scaling the data\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "\n",
    "X_scaled = sc_X.fit_transform(X)\n",
    "y_scaled = sc_y.fit_transform(y.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Train the SVR model with a polynomial kernel\n",
    "svr_poly = SVR(kernel='poly', degree=3, C=100, epsilon=0.1)\n",
    "svr_poly.fit(X_scaled, y_scaled)\n",
    "\n",
    "# 1. Compute the 95th percentiles for each feature (for input ranges)\n",
    "percentiles = np.percentile(X, 95, axis=0)\n",
    "\n",
    "# 2. Plot Partial Poly Graphs for each feature\n",
    "for feature_index in range(X.shape[1]):\n",
    "    # Vary the current feature (e.g., X1) across the top 95 percentile range\n",
    "    feature_range = np.linspace(0, percentiles[feature_index], 1000).reshape(-1, 1)\n",
    "\n",
    "    # Fix the other features at their mean values\n",
    "    X_fixed = np.mean(X[:, np.arange(X.shape[1]) != feature_index], axis=0)\n",
    "\n",
    "    # Create the combined input data with the varied feature and fixed others\n",
    "    X_combined = np.hstack([feature_range, np.tile(X_fixed, (feature_range.shape[0], 1))])\n",
    "\n",
    "    # Scale the new data for prediction\n",
    "    X_combined_scaled = sc_X.transform(X_combined)\n",
    "\n",
    "    # Predict using the trained SVR model\n",
    "    y_pred_scaled = svr_poly.predict(X_combined_scaled)\n",
    "\n",
    "    # Inverse transform the predictions to get original scale\n",
    "    y_pred = sc_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "    # Plot the result\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(feature_range, y_pred, label=f\"SVR Polynomial Fit (Varying Feature {feature_index+1})\")\n",
    "    plt.title(f'Partial Poly Graph (Varying Feature {feature_index+1})')\n",
    "    plt.xlabel(f'Feature {feature_index+1}')\n",
    "    plt.ylabel('Predicted y')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 3. Plot Partial Dependence for Pairs of Features (2D Contour Plots)\n",
    "for i in range(X.shape[1]):\n",
    "    for j in range(i + 1, X.shape[1]):\n",
    "        # Create a grid of values for Feature i and Feature j\n",
    "        feature1_range = np.linspace(0, percentiles[i], 100)\n",
    "        feature2_range = np.linspace(0, percentiles[j], 100)\n",
    "        \n",
    "        # Create a meshgrid for the 2D grid of Feature i and Feature j\n",
    "        feature1_grid, feature2_grid = np.meshgrid(feature1_range, feature2_range)\n",
    "        \n",
    "        # Create a combined grid of features for prediction\n",
    "        X_grid = np.vstack([feature1_grid.ravel(), feature2_grid.ravel()]).T\n",
    "        \n",
    "        # Fix the other features at their mean value\n",
    "        X_fixed = np.mean(X[:, [k for k in range(X.shape[1]) if k != i and k != j]], axis=0)\n",
    "        \n",
    "        # Combine the grid values with the fixed feature values\n",
    "        X_combined = np.hstack([X_grid, np.full((X_grid.shape[0], len(X_fixed)), X_fixed)])\n",
    "\n",
    "        # Scale the new data for prediction\n",
    "        X_combined_scaled = sc_X.transform(X_combined)\n",
    "\n",
    "        # Predict using the trained SVR model\n",
    "        y_pred_scaled = svr_poly.predict(X_combined_scaled)\n",
    "\n",
    "        # Inverse transform the predictions to get original scale\n",
    "        y_pred = sc_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "        # Reshape the predictions back into the grid shape\n",
    "        y_pred_grid = y_pred.reshape(feature1_grid.shape)\n",
    "\n",
    "        # Plot the results as a contour plot (for 2D data)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.contourf(feature1_range, feature2_range, y_pred_grid, levels=50, cmap='coolwarm')\n",
    "        plt.colorbar(label='Predicted y')\n",
    "        plt.title(f'Partial Dependence (Varying Features {i+1} and {j+1})')\n",
    "        plt.xlabel(f'Feature {i+1}')\n",
    "        plt.ylabel(f'Feature {j+1}')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072f928c",
   "metadata": {},
   "source": [
    "# Finding optimum using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f8f756a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 69 is out of bounds for axis 1 with size 69",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Define a realistic search box (stay inside observed data to avoid extrapolation) for random search and finding best time\u001b[39;00m\n\u001b[32m      2\u001b[39m percentiles = (\u001b[32m0.05\u001b[39m, \u001b[32m0.95\u001b[39m)\n\u001b[32m      3\u001b[39m bounds = {\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     f: (np.percentile(\u001b[43mX_scaled\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m, percentiles[\u001b[32m0\u001b[39m] * \u001b[32m100\u001b[39m), \n\u001b[32m      5\u001b[39m         np.percentile(X_scaled[:, X.columns.get_loc(f)], percentiles[\u001b[32m1\u001b[39m] * \u001b[32m100\u001b[39m))\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m X.columns\n\u001b[32m      7\u001b[39m }\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Random search over the fitted model’s prediction surface\u001b[39;00m\n\u001b[32m     10\u001b[39m rng = np.random.default_rng(\u001b[32m42\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: index 69 is out of bounds for axis 1 with size 69"
     ]
    }
   ],
   "source": [
    "# Define a realistic search box (stay inside observed data to avoid extrapolation) for random search and finding best time\n",
    "percentiles = (0.05, 0.95)\n",
    "bounds = {\n",
    "    f: (np.percentile(X_scaled[:, X.columns.get_loc(f)], percentiles[0] * 100), \n",
    "        np.percentile(X_scaled[:, X.columns.get_loc(f)], percentiles[1] * 100))\n",
    "    for f in X.columns\n",
    "}\n",
    "\n",
    "# Random search over the fitted model’s prediction surface\n",
    "rng = np.random.default_rng(42)\n",
    "N = 50000\n",
    "candidates = {\n",
    "    f: rng.uniform(low=b[0], high=b[1], size=N)\n",
    "    for f, b in bounds.items()\n",
    "}\n",
    "Xcand = pd.DataFrame(candidates)[X.columns]\n",
    "ycand = grid_poly.predict(Xcand.drop(columns=[\"const\"]))\n",
    "\n",
    "imin = int(np.argmin(ycand))\n",
    "best_combo = Xcand.iloc[imin].to_dict()\n",
    "best_pred  = ycand[imin]\n",
    "\n",
    "print(\"=== Model-suggested first brake setup (within observed range) ===\")\n",
    "for k, v in best_combo.items():\n",
    "    print(f\"{k}: {v:,.4f}\")\n",
    "print(f\"Predicted Target_CURRENTLAPTIMEINMS: {best_pred:,.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8481240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
